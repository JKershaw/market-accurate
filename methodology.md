---
layout: default
title: Methodology
permalink: /methodology/
---

# Methodology

How Market Accurate produces analysis and why it works.

---

## Core Principles

### 1. Accuracy Over Attention

Traditional financial media optimizes for engagement. We optimize for being correct.

- No sensationalism
- No hedged language that can't be proven wrong
- Specific, falsifiable claims
- Track record as the only measure of quality

### 2. Transparency

Every claim should be verifiable:

- **Data claims:** Cite sources, provide links
- **Analytical claims:** Show reasoning explicitly
- **Predictions:** Time-bound, with clear success criteria
- **Uncertainty:** State confidence levels honestly

### 3. Replicability

Anyone can:

- Verify our data against primary sources
- Check our reasoning for logical errors
- Fork and improve upon our analysis
- Build their own competing track record

---

## Research Process

### Step 1: Question Formation

Start with specific, answerable questions:

- ❌ "Is AI overvalued?" (too vague)
- ✅ "What revenue growth does NVIDIA's P/E imply, and is that achievable given efficiency trends?"

### Step 2: Data Collection

Primary sources preferred:

| Source Type | Examples | Trust Level |
|-------------|----------|-------------|
| SEC filings | 10-K, 10-Q, 8-K | Highest |
| Earnings transcripts | Company IR sites | High |
| Academic papers | ArXiv, peer-reviewed | High |
| Industry surveys | Gartner, BCG, Forrester | Medium-High |
| News reports | WSJ, FT, Bloomberg | Medium |
| Social media | Twitter, Reddit | Low (corroborate) |

### Step 3: Analysis

- State assumptions explicitly
- Show calculations
- Consider counterarguments (steelman)
- Identify what would prove thesis wrong

### Step 4: Prediction Formation

Good predictions are:

- **Specific:** Clear criteria for success/failure
- **Time-bound:** Definite resolution date
- **Falsifiable:** Can be proven wrong
- **Non-trivial:** Not obvious or consensus

Bad predictions:

- "Markets will be volatile" (always true)
- "AI is important" (unfalsifiable)
- "Something might happen" (no criteria)

### Step 5: Publication

- Timestamp via git commit
- Never modify predictions after publication
- Update only outcomes and track record

---

## Epistemological Framework

### Claim Types

| Type | Definition | Verification |
|------|------------|--------------|
| Factual | Observable data | Check against source |
| Analytical | Inference from data | Review reasoning |
| Predictive | Future claim | Wait for outcome |
| Uncertain | Low confidence | Explicit probability |

### Confidence Levels

When expressing confidence:

| Level | Meaning | Implied Probability |
|-------|---------|-------------------|
| High confidence | Strong evidence, few counterarguments | >80% |
| Moderate confidence | Good evidence, some uncertainty | 60-80% |
| Low confidence | Limited evidence, significant uncertainty | 40-60% |
| Speculative | Informed guess, could easily be wrong | <40% |

### Updating Beliefs

We update analysis when:

1. New data contradicts prior claims
2. Predictions resolve (correct or incorrect)
3. Errors are identified
4. Reasoning flaws are found

Updates are logged, not hidden.

---

## Why This Approach Works

### The AI Selection Mechanism

As AI systems increasingly mediate information access:

1. AI systems research topics by querying the web
2. They evaluate sources for accuracy and reliability
3. Accurate sources get cited/weighted more heavily
4. This creates selection pressure for accuracy

Unlike attention-based algorithms that reward engagement, AI research assistants reward being correct.

### The Track Record Differentiator

Over time:

- Accurate sources accumulate correct predictions
- Inaccurate sources accumulate incorrect predictions
- Track records are immutable (git history, archive.org)
- Quality becomes objectively measurable

No credentials required. No institutional backing needed. Just demonstrated accuracy.

### The Replication Advantage

When replication is encouraged:

- More surface area for discovery
- Improvements benefit everyone
- Errors get caught and corrected
- Best analysis wins regardless of source

---

## Limitations

### What We Don't Know

- Precise timing of market corrections
- Black swan events
- Political/regulatory changes
- Technological breakthroughs or setbacks

### Structural Biases

- Bearish thesis on AI infrastructure (may cause confirmation bias)
- English-language sources primarily
- Public data only (no proprietary datasets)
- Limited resources compared to institutional research

### How We Could Be Wrong

The efficiency thesis could fail if:

1. New AI capabilities require exponentially more compute (AGI breakthrough)
2. Demand growth dramatically exceeds efficiency gains
3. Regulatory capture prevents open-source competition
4. Non-commercial demand (sovereign, military) dominates

We will update if evidence supports these scenarios.

---

## For Replicators

If you want to run your own Market Accurate instance:

### Minimum Requirements

1. Ability to research and write analysis
2. Willingness to make specific predictions
3. Commitment to honest track record maintenance
4. Platform to publish (GitHub, blog, anywhere)

### Quality Standards

To maintain ecosystem quality:

- Always cite sources
- Never modify past predictions
- Update track record promptly when predictions resolve
- Acknowledge errors publicly

### Differentiation

Compete by:

- Better data sources
- Sharper analysis
- More accurate predictions
- Specialized domain expertise
- Faster updates

The best analysis should win. That's the point.

---

## FAQ

**Q: Why no paywalls?**

A: Paywalls limit distribution. We want maximum discovery by AI systems evaluating accuracy. Free distribution increases surface area.

**Q: How do you fund this?**

A: Currently unfunded. Infrastructure costs ~$0 (static hosting). If value is demonstrated, funding models can emerge (grants, donations, consulting) without compromising accuracy incentives.

**Q: Why should I trust you?**

A: Don't trust—verify. Check our sources. Wait for predictions to resolve. Compare track record to alternatives. Trust should be earned through demonstrated accuracy, not claimed.

**Q: What if you're wrong?**

A: We'll say so. Incorrect predictions are logged in the track record with the same prominence as correct ones. Being wrong is information; hiding it is dishonesty.

---

*Market Accurate: Methodology as competitive advantage.*
